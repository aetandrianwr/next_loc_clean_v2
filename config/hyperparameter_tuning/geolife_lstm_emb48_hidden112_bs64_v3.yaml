# LSTM Hyperparameter Tuning - Geolife v3
# Larger batch size and higher lr for small dataset
# Config: base_emb=48, hidden=112, layers=2, ~427K params

seed: 42

data:
  data_dir: data/geolife_eps20/processed
  dataset_prefix: geolife_eps20_prev7
  dataset: geolife
  experiment_root: experiments

training:
  if_embed_user: true
  if_embed_poi: false
  if_embed_time: true
  if_embed_duration: true
  previous_day: 7
  verbose: true
  debug: false
  batch_size: 64
  print_step: 10
  num_workers: 0
  day_selection: default

dataset_info:
  total_loc_num: 1187
  total_user_num: 46

embedding:
  base_emb_size: 48
  poi_original_size: 16

model:
  networkName: lstm
  lstm_hidden_size: 112
  lstm_num_layers: 2
  lstm_dropout: 0.15
  fc_dropout: 0.15

optimiser:
  optimizer: Adam
  max_epoch: 50
  lr: 0.002
  weight_decay: 0.00001
  beta1: 0.9
  beta2: 0.999
  momentum: 0.98
  num_warmup_epochs: 2
  num_training_epochs: 50
  patience: 5
  lr_step_size: 1
  lr_gamma: 0.1
