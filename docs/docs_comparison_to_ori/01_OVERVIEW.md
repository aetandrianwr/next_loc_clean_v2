# Comprehensive Comparison: Proposed Model vs Original Pointer-Generator

## Document Index

This documentation provides a complete A-to-Z comparison between:
- **Proposed Model**: `PointerGeneratorTransformer` (PyTorch) - Location: `src/models/proposed/pgt.py`
- **Original Model**: Pointer-Generator Network (TensorFlow) - Location: `pointer-generator/`

---

## ğŸ“š Documentation Structure

| Document | Description |
|----------|-------------|
| [01_OVERVIEW.md](01_OVERVIEW.md) | This file - High-level overview and navigation |
| [02_ARCHITECTURE_COMPARISON.md](02_ARCHITECTURE_COMPARISON.md) | Architecture diagrams and component comparison |
| [03_ENCODER_COMPARISON.md](03_ENCODER_COMPARISON.md) | Detailed encoder analysis (LSTM vs Transformer) |
| [04_ATTENTION_MECHANISM.md](04_ATTENTION_MECHANISM.md) | Attention mechanism deep dive |
| [05_POINTER_GENERATION_GATE.md](05_POINTER_GENERATION_GATE.md) | Pointer-generation gate mechanism |
| [06_EMBEDDING_COMPARISON.md](06_EMBEDDING_COMPARISON.md) | Embedding layers and feature engineering |
| [07_TRAINING_PIPELINE.md](07_TRAINING_PIPELINE.md) | Training configuration and optimization |
| [08_DATA_PROCESSING.md](08_DATA_PROCESSING.md) | Data loading and batching strategies |
| [09_LOSS_AND_METRICS.md](09_LOSS_AND_METRICS.md) | Loss functions and evaluation metrics |
| [10_DEFAULT_CONFIGURATION.md](10_DEFAULT_CONFIGURATION.md) | Default hyperparameter comparison |
| [11_CODE_WALKTHROUGH_PROPOSED.md](11_CODE_WALKTHROUGH_PROPOSED.md) | Line-by-line code analysis (Proposed) |
| [12_CODE_WALKTHROUGH_ORIGINAL.md](12_CODE_WALKTHROUGH_ORIGINAL.md) | Line-by-line code analysis (Original) |
| [13_MATHEMATICAL_FORMULATION.md](13_MATHEMATICAL_FORMULATION.md) | Mathematical equations and derivations |
| [14_EXAMPLE_WALKTHROUGH.md](14_EXAMPLE_WALKTHROUGH.md) | End-to-end example with actual data |
| [15_JUSTIFICATION_OF_CHANGES.md](15_JUSTIFICATION_OF_CHANGES.md) | Why each change was made |
| [16_SUMMARY_AND_CONCLUSIONS.md](16_SUMMARY_AND_CONCLUSIONS.md) | Final summary and key takeaways |

---

## ğŸ¯ Executive Summary

### What is the Original Pointer-Generator Network?

The original Pointer-Generator Network (See et al., 2017) was designed for **text summarization**. It combines:
1. A **sequence-to-sequence architecture** with attention
2. A **pointer mechanism** to copy words from source text
3. A **coverage mechanism** to avoid repetition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ORIGINAL POINTER-GENERATOR                       â”‚
â”‚                  (Text Summarization)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: Article text (words)                                     â”‚
â”‚  Output: Summary text (words)                                    â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Encoder  â”‚ â†’  â”‚ Attentionâ”‚ â†’  â”‚ Decoder  â”‚ â†’  â”‚ Output   â”‚  â”‚
â”‚  â”‚ (BiLSTM) â”‚    â”‚  Layer   â”‚    â”‚  (LSTM)  â”‚    â”‚ (Vocab)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  Framework: TensorFlow 1.x                                       â”‚
â”‚  Task: Many-to-Many (sequence generation)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What is the Proposed PointerGeneratorTransformer?

The Proposed Model adapts the pointer-generator concept for **next location prediction**. Key adaptations:
1. **Transformer encoder** instead of BiLSTM
2. **Rich temporal features** (time, weekday, duration, recency)
3. **Single-step prediction** (next location only)
4. **User personalization** through user embeddings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PROPOSED POINTERNETWORKV45                      â”‚
â”‚                  (Next Location Prediction)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: Location history + Temporal features + User ID          â”‚
â”‚  Output: Next location (single prediction)                       â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Feature  â”‚ â†’  â”‚Transformerâ”‚ â†’  â”‚ Pointer  â”‚ â†’  â”‚Combined  â”‚  â”‚
â”‚  â”‚ Fusion   â”‚    â”‚ Encoder  â”‚    â”‚ + Gen    â”‚    â”‚ Output   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  Framework: PyTorch                                              â”‚
â”‚  Task: Many-to-One (classification)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ High-Level Comparison Table

| Aspect | Original Pointer-Generator | Proposed PointerGeneratorTransformer |
|--------|---------------------------|---------------------------|
| **Task Domain** | Text Summarization (NLP) | Next Location Prediction (Mobility) |
| **Framework** | TensorFlow 1.x | PyTorch |
| **Input Type** | Word sequences | Location + Temporal sequences |
| **Output Type** | Word sequence (generation) | Single location (classification) |
| **Encoder** | Bidirectional LSTM | Transformer Encoder |
| **Decoder** | Unidirectional LSTM | None (single-step output) |
| **Attention** | Bahdanau-style additive | Scaled dot-product |
| **Position Encoding** | None (LSTM captures order) | Sinusoidal + Position-from-end |
| **User Modeling** | None | User embeddings |
| **Temporal Features** | None | Time, weekday, duration, recency |
| **Vocabulary Handling** | Extended vocabulary for OOVs | Fixed location vocabulary |
| **Coverage Mechanism** | Yes (optional) | No |
| **Beam Search** | Yes | No (argmax) |

---

## ğŸ“Š Running Example: User's Day Trip

Throughout this documentation, we'll use a consistent example to illustrate concepts:

### Example Scenario

**User**: Alice (user_id = 42)  
**Date**: Monday, January 13, 2026  
**Goal**: Predict where Alice will go next

**Location History** (past 5 visits):
| Step | Location | Location ID | Time | Duration | Days Ago |
|------|----------|-------------|------|----------|----------|
| 1 | Home | 101 | 07:30 | 90 min | 0 |
| 2 | Coffee Shop | 205 | 09:00 | 30 min | 0 |
| 3 | Office | 150 | 09:30 | 240 min | 0 |
| 4 | Restaurant | 312 | 14:00 | 60 min | 0 |
| 5 | Office | 150 | 15:00 | 180 min | 0 |

**True Next Location**: Gym (location_id = 89) at 18:00

### Why This Example?

This example demonstrates:
1. **Repeated locations**: Office (150) appears twice â†’ pointer should learn this
2. **Temporal patterns**: Work hours â†’ common office visits
3. **User habits**: Alice goes to gym after work
4. **Weekday patterns**: Monday is a workday

---

## ğŸ—ï¸ Conceptual Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           INPUT PROCESSING                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  ORIGINAL:                           PROPOSED:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Word Embeddings â”‚                 â”‚ Location Embedding (d_model)        â”‚    â”‚
â”‚  â”‚   [vocab_size   â”‚                 â”‚ User Embedding (d_model)            â”‚    â”‚
â”‚  â”‚    Ã— emb_dim]   â”‚                 â”‚ Time Embedding (d_model/4)          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚ Weekday Embedding (d_model/4)       â”‚    â”‚
â”‚           â”‚                          â”‚ Duration Embedding (d_model/4)      â”‚    â”‚
â”‚           â”‚                          â”‚ Recency Embedding (d_model/4)       â”‚    â”‚
â”‚           â”‚                          â”‚ Position-from-End Emb (d_model/4)   â”‚    â”‚
â”‚           â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                           â”‚                          â”‚
â”‚           â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚           â”‚                          â”‚  Feature Fusion (Linear + LayerNorm) â”‚    â”‚
â”‚           â”‚                          â”‚  [concat_dim â†’ d_model]              â”‚    â”‚
â”‚           â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                           â”‚                          â”‚
â”‚           â–¼                                           â–¼                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              ENCODER                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  ORIGINAL:                           PROPOSED:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Bidirectional   â”‚                 â”‚ Transformer Encoder                 â”‚    â”‚
â”‚  â”‚     LSTM        â”‚                 â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚ â”‚  Self-Attention (Multi-Head)    â”‚ â”‚    â”‚
â”‚  â”‚ Forward LSTM â†’  â”‚                 â”‚ â”‚  + Pre-LayerNorm               â”‚ â”‚    â”‚
â”‚  â”‚ â† Backward LSTM â”‚                 â”‚ â”‚  + GELU FFN                    â”‚ â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚ â”‚  Ã— num_layers                  â”‚ â”‚    â”‚
â”‚  â”‚ Output: 2Ã—hiddenâ”‚                 â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚                                     â”‚    â”‚
â”‚           â”‚                          â”‚ + Sinusoidal Positional Encoding    â”‚    â”‚
â”‚           â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â–¼                                           â–¼                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                           ATTENTION & POINTER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  ORIGINAL:                           PROPOSED:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Bahdanau        â”‚                 â”‚ Scaled Dot-Product Attention        â”‚    â”‚
â”‚  â”‚ Attention       â”‚                 â”‚                                     â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚ Q = Linear(context)                 â”‚    â”‚
â”‚  â”‚ e = v^T tanh(   â”‚                 â”‚ K = Linear(encoded)                 â”‚    â”‚
â”‚  â”‚   W_hÂ·h + W_sÂ·s â”‚                 â”‚ score = QÂ·K^T / âˆšd_model            â”‚    â”‚
â”‚  â”‚   + b)          â”‚                 â”‚ + position_bias                     â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚                                     â”‚    â”‚
â”‚  â”‚ Î± = softmax(e)  â”‚                 â”‚ ptr_probs = softmax(score)          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                           â”‚                          â”‚
â”‚           â–¼                                           â–¼                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                       POINTER-GENERATION MECHANISM                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  ORIGINAL:                           PROPOSED:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ p_gen = sigmoid(â”‚                 â”‚ gate = MLP(context)                 â”‚    â”‚
â”‚  â”‚   w_cÂ·c + w_sÂ·s â”‚                 â”‚   â†’ Linear(d_model, d_model/2)      â”‚    â”‚
â”‚  â”‚   + w_xÂ·x + b)  â”‚                 â”‚   â†’ GELU                            â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚   â†’ Linear(d_model/2, 1)            â”‚    â”‚
â”‚  â”‚ P = p_genÃ—P_vocabâ”‚                â”‚   â†’ Sigmoid                         â”‚    â”‚
â”‚  â”‚   +(1-p_gen)Ã—Î±  â”‚                 â”‚                                     â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚ P = gateÃ—ptr_dist                   â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚   +(1-gate)Ã—gen_probs               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                                           â”‚                          â”‚
â”‚           â–¼                                           â–¼                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                              OUTPUT                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                  â”‚
â”‚  ORIGINAL:                           PROPOSED:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Extended Vocab  â”‚                 â”‚ Fixed Location Vocabulary           â”‚    â”‚
â”‚  â”‚ Distribution    â”‚                 â”‚                                     â”‚    â”‚
â”‚  â”‚                 â”‚                 â”‚ log_probs = log(final_probs + Îµ)    â”‚    â”‚
â”‚  â”‚ + Beam Search   â”‚                 â”‚                                     â”‚    â”‚
â”‚  â”‚ for decoding    â”‚                 â”‚ prediction = argmax(log_probs)      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Differences at a Glance

### 1. Task Difference
```
ORIGINAL (Text Summarization):
  "The quick brown fox jumps..." â†’ "Fox jumps over dog"
  - Input: Variable length text
  - Output: Variable length summary
  - Multiple decoder steps

PROPOSED (Next Location):
  [Home, Coffee, Office, Restaurant, Office] â†’ [Gym]
  - Input: Location sequence with temporal context
  - Output: Single next location
  - Single prediction step
```

### 2. Encoder Difference
```
ORIGINAL: BiLSTM
  - Sequential processing (O(n) time)
  - Good for capturing local dependencies
  - Fixed 256 hidden units

PROPOSED: Transformer
  - Parallel processing (O(1) parallel time)
  - Global attention across all positions
  - Configurable d_model (default: 64-128)
```

### 3. Feature Representation
```
ORIGINAL:
  Input = WordEmbedding(token)
  
PROPOSED:
  Input = Concat([
    LocationEmb(loc),
    UserEmb(user),
    TimeEmb(time),
    WeekdayEmb(weekday),
    DurationEmb(duration),
    RecencyEmb(diff),
    PositionFromEndEmb(pos)
  ])
```

---

## ğŸ“ˆ Why These Changes?

The changes from original to proposed are motivated by domain-specific requirements:

| Original Design Choice | Proposed Adaptation | Justification |
|----------------------|---------------------|---------------|
| Word embeddings only | Multi-feature embeddings | Mobility requires temporal context |
| No user modeling | User embeddings | Location preferences are personal |
| BiLSTM encoder | Transformer encoder | Better parallelization, global context |
| Multi-step decoder | Single-step output | Only need next location |
| Beam search | Argmax | Classification task, not generation |
| Coverage mechanism | Position bias | Prevent attending to padding |
| Extended vocabulary | Fixed vocabulary | Locations are known entities |

---

## ğŸ“– How to Use This Documentation

### For Understanding the Comparison:
1. Start with this overview (01_OVERVIEW.md)
2. Read Architecture Comparison (02)
3. Deep dive into specific components (03-09)

### For Implementation Details:
1. Read Code Walkthroughs (11-12)
2. Check Mathematical Formulations (13)
3. Follow the Example Walkthrough (14)

### For PhD Thesis Reference:
1. Use Mathematical Formulations (13) for equations
2. Use Justification of Changes (15) for design decisions
3. Use Summary (16) for conclusions

---

## ğŸ“š References

1. See, A., Liu, P. J., & Manning, C. D. (2017). Get To The Point: Summarization with Pointer-Generator Networks. ACL 2017.
2. Vaswani, A., et al. (2017). Attention Is All You Need. NeurIPS 2017.
3. Vinyals, O., Fortunato, M., & Jaitly, N. (2015). Pointer Networks. NeurIPS 2015.

---

*Last Updated: January 13, 2026*
