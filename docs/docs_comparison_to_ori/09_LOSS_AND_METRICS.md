# Loss Functions and Metrics Comparison

## Table of Contents
1. [Overview](#overview)
2. [Loss Functions](#loss-functions)
3. [Evaluation Metrics](#evaluation-metrics)
4. [Coverage Mechanism](#coverage-mechanism)
5. [Mathematical Formulations](#mathematical-formulations)
6. [Code Comparison](#code-comparison)
7. [Example Calculations](#example-calculations)

---

## Overview

| Aspect | Original | Proposed |
|--------|----------|----------|
| **Primary Loss** | Negative Log Likelihood | Cross-Entropy |
| **Secondary Loss** | Coverage Loss (optional) | None |
| **Label Smoothing** | No | Yes (0.03) |
| **Primary Metric** | ROUGE (1, 2, L) | Accuracy@K, MRR, NDCG |
| **Task Type** | Sequence Generation | Classification |

---

## Loss Functions

### Original: Negative Log Likelihood + Coverage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORIGINAL LOSS FUNCTIONS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. PRIMARY LOSS: Negative Log Likelihood                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  For each decoding step t:                                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    L_t = -log P(y_t* | y_{<t}, x)                                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    y_t* = correct target word at step t                             â”‚   â”‚
â”‚  â”‚    P(y_t*) = probability of correct word from final distribution    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Total Loss:                                                         â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           1      T                                                   â”‚   â”‚
â”‚  â”‚    L = â”€â”€â”€â”€â”€â”€â”€ Ã— Î£ L_t Ã— mask_t                                     â”‚   â”‚
â”‚  â”‚         T_valid  t=1                                                 â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    T_valid = number of non-padding tokens                           â”‚   â”‚
â”‚  â”‚    mask_t = 1 if t is not padding, 0 otherwise                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  2. COVERAGE LOSS (Optional):                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Coverage vector tracks attention history:                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    c_t = Î£_{t'=1}^{t-1} a_{t'}                                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Coverage loss penalizes repeated attention:                         â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    L_cov_t = Î£_i min(a_{t,i}, c_{t,i})                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Total coverage loss:                                                â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚             1      T                                                 â”‚   â”‚
â”‚  â”‚    L_cov = â”€â”€â”€â”€â”€ Ã— Î£ L_cov_t Ã— mask_t                               â”‚   â”‚
â”‚  â”‚            T_valid t=1                                               â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Final loss with coverage:                                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    L_total = L + Î» Ã— L_cov                                          â”‚   â”‚
â”‚  â”‚              â†‘       â†‘                                               â”‚   â”‚
â”‚  â”‚              NLL     Coverage (Î» = 1.0 default)                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Proposed: Cross-Entropy with Label Smoothing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROPOSED LOSS FUNCTION                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Cross-Entropy Loss with Label Smoothing:                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Standard Cross-Entropy:                                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    L_CE = -log P(y* | x)                                            â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    y* = correct target location                                     â”‚   â”‚
â”‚  â”‚    P(y*) = model's probability for correct location                 â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  With Label Smoothing (Îµ = 0.03):                                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    Target distribution:                                              â”‚   â”‚
â”‚  â”‚      q(y=y*) = 1 - Îµ = 0.97                                         â”‚   â”‚
â”‚  â”‚      q(yâ‰ y*) = Îµ/(K-1)  for all other classes                       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    Smoothed Loss:                                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚      L_smooth = -Î£_k q(k) Ã— log P(k)                                â”‚   â”‚
â”‚  â”‚               = -(1-Îµ)Ã—log P(y*) - ÎµÃ—(1/(K-1))Ã—Î£_{kâ‰ y*} log P(k)   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Benefits:                                                           â”‚   â”‚
â”‚  â”‚    - Prevents overconfident predictions                             â”‚   â”‚
â”‚  â”‚    - Regularization effect                                          â”‚   â”‚
â”‚  â”‚    - Better generalization                                          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  No coverage loss needed:                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  - Single-step prediction (no decoder sequence)                     â”‚   â”‚
â”‚  â”‚  - No sequential attention to track                                 â”‚   â”‚
â”‚  â”‚  - No repetition problem                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Evaluation Metrics

### Original: ROUGE Scores

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORIGINAL: ROUGE METRICS                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ROUGE-1 (Unigram Overlap):                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           |Generated âˆ© Reference|                                    â”‚   â”‚
â”‚  â”‚  R-1_P = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚              |Generated|                                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           |Generated âˆ© Reference|                                    â”‚   â”‚
â”‚  â”‚  R-1_R = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚   â”‚
â”‚  â”‚              |Reference|                                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           2 Ã— R-1_P Ã— R-1_R                                         â”‚   â”‚
â”‚  â”‚  R-1_F = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚   â”‚
â”‚  â”‚           R-1_P + R-1_R                                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Example:                                                            â”‚   â”‚
â”‚  â”‚    Generated: "president announces economic policy"                  â”‚   â”‚
â”‚  â”‚    Reference: "president unveils new economic plan"                  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    Overlap: {president, economic} = 2 words                         â”‚   â”‚
â”‚  â”‚    P = 2/4 = 0.50, R = 2/5 = 0.40, F = 0.444                       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  ROUGE-2 (Bigram Overlap):                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Same as ROUGE-1 but with bigrams                                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Example:                                                            â”‚   â”‚
â”‚  â”‚    Generated bigrams: {"president announces", "announces economic",  â”‚   â”‚
â”‚  â”‚                        "economic policy"}                            â”‚   â”‚
â”‚  â”‚    Reference bigrams: {"president unveils", "unveils new",          â”‚   â”‚
â”‚  â”‚                        "new economic", "economic plan"}             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    Overlap: {} = 0 bigrams                                          â”‚   â”‚
â”‚  â”‚    R-2_F = 0.0                                                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  ROUGE-L (Longest Common Subsequence):                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           LCS(Generated, Reference)                                  â”‚   â”‚
â”‚  â”‚  R-L_P = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚   â”‚
â”‚  â”‚              |Generated|                                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           LCS(Generated, Reference)                                  â”‚   â”‚
â”‚  â”‚  R-L_R = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚   â”‚
â”‚  â”‚              |Reference|                                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Example:                                                            â”‚   â”‚
â”‚  â”‚    Generated: "president announces economic policy"                  â”‚   â”‚
â”‚  â”‚    Reference: "president unveils new economic plan"                  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    LCS: "president economic" (length 2)                             â”‚   â”‚
â”‚  â”‚    R-L_P = 2/4 = 0.50, R-L_R = 2/5 = 0.40                          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Proposed: Classification Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROPOSED: CLASSIFICATION METRICS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Accuracy@K (Top-K Accuracy):                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           # samples where y* âˆˆ top-K predictions                    â”‚   â”‚
â”‚  â”‚  Acc@K = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚   â”‚
â”‚  â”‚                     Total samples                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Example:                                                            â”‚   â”‚
â”‚  â”‚    Model predictions (sorted by prob):                              â”‚   â”‚
â”‚  â”‚      [loc_150, loc_89, loc_101, loc_205, ...]                       â”‚   â”‚
â”‚  â”‚    True target: loc_89                                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    Acc@1 = 0 (loc_89 not in top-1)                                  â”‚   â”‚
â”‚  â”‚    Acc@5 = 1 (loc_89 in top-5)                                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Common K values: 1, 5, 10                                          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  MRR (Mean Reciprocal Rank):                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚        1   N    1                                                    â”‚   â”‚
â”‚  â”‚  MRR = â”€ Ã— Î£  â”€â”€â”€â”€â”€                                                 â”‚   â”‚
â”‚  â”‚        N  i=1  rank_i                                                â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where rank_i = position of correct answer in prediction list       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Example:                                                            â”‚   â”‚
â”‚  â”‚    Sample 1: True=loc_89, Rank=2  â†’ 1/2 = 0.50                      â”‚   â”‚
â”‚  â”‚    Sample 2: True=loc_101, Rank=1 â†’ 1/1 = 1.00                      â”‚   â”‚
â”‚  â”‚    Sample 3: True=loc_205, Rank=5 â†’ 1/5 = 0.20                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    MRR = (0.50 + 1.00 + 0.20) / 3 = 0.567                          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  NDCG@K (Normalized Discounted Cumulative Gain):                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚          DCG@K                                                       â”‚   â”‚
â”‚  â”‚  NDCG = â”€â”€â”€â”€â”€â”€â”€â”€ (always 1 or 0 for single-label classification)   â”‚   â”‚
â”‚  â”‚         IDCG@K                                                       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  For single-label classification:                                    â”‚   â”‚
â”‚  â”‚    NDCG@K = 1 if correct label in top-K, else 0                     â”‚   â”‚
â”‚  â”‚    (Same as Acc@K, but NDCG is more general for ranked retrieval)   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Metrics Comparison Table

| Metric | Original | Proposed | Purpose |
|--------|----------|----------|---------|
| **ROUGE-1** | âœ“ | âœ— | Word overlap (generation quality) |
| **ROUGE-2** | âœ“ | âœ— | Bigram overlap (fluency) |
| **ROUGE-L** | âœ“ | âœ— | Longest common subsequence |
| **Acc@1** | âœ— | âœ“ | Exact match accuracy |
| **Acc@5** | âœ— | âœ“ | Top-5 accuracy |
| **Acc@10** | âœ— | âœ“ | Top-10 accuracy |
| **MRR** | âœ— | âœ“ | Average reciprocal rank |
| **NDCG@K** | âœ— | âœ“ | Ranking quality |
| **Loss** | âœ“ | âœ“ | Training objective |

---

## Coverage Mechanism

### Original: Coverage to Prevent Repetition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ORIGINAL: COVERAGE MECHANISM                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Problem: Repetitive summaries                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Input: "The president met with congress about healthcare policy.   â”‚   â”‚
â”‚  â”‚          Healthcare reform is a priority..."                        â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Without coverage:                                                   â”‚   â”‚
â”‚  â”‚    "President discusses healthcare. President discusses healthcare. â”‚   â”‚
â”‚  â”‚     President discusses healthcare..."                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  With coverage:                                                      â”‚   â”‚
â”‚  â”‚    "President discusses healthcare reform with congress."           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Solution: Track cumulative attention                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 1: c_1 = 0 (no history yet)                                   â”‚   â”‚
â”‚  â”‚          Attend to "president" â†’ a_1 = [0.3, 0.1, 0.05, ...]       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 2: c_2 = a_1 (history from step 1)                           â”‚   â”‚
â”‚  â”‚          "president" already has attention 0.3                      â”‚   â”‚
â”‚  â”‚          Coverage encourages attending elsewhere                    â”‚   â”‚
â”‚  â”‚          Attend to "healthcare" â†’ a_2 = [0.05, 0.4, 0.1, ...]      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 3: c_3 = a_1 + a_2                                           â”‚   â”‚
â”‚  â”‚          "president"=0.35, "healthcare"=0.5 already attended       â”‚   â”‚
â”‚  â”‚          Attend to "congress" â†’ a_3 = [0.02, 0.05, 0.3, ...]       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Coverage Loss Calculation:                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  L_cov_t = Î£_i min(a_{t,i}, c_{t,i})                                â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Example at step 2:                                                  â”‚   â”‚
â”‚  â”‚    a_2 = [0.05, 0.4, 0.1, ...]                                     â”‚   â”‚
â”‚  â”‚    c_2 = [0.30, 0.1, 0.05, ...]                                    â”‚   â”‚
â”‚  â”‚    min = [0.05, 0.1, 0.05, ...]                                    â”‚   â”‚
â”‚  â”‚    L_cov_2 = 0.05 + 0.1 + 0.05 + ... = 0.20                        â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Loss penalizes re-attending to already-attended positions          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Proposed: No Coverage Needed

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROPOSED: NO COVERAGE MECHANISM                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Why not needed:                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  1. Single-step prediction (not sequence generation)                â”‚   â”‚
â”‚  â”‚     - Only one output: the next location                            â”‚   â”‚
â”‚  â”‚     - No decoder loop, no sequential attention                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  2. No repetition problem                                           â”‚   â”‚
â”‚  â”‚     - Cannot repeat output (single prediction)                      â”‚   â”‚
â”‚  â”‚     - No attention history to track                                 â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  3. Attention is computed once                                      â”‚   â”‚
â”‚  â”‚     - Query (single prediction vector) â†’ attention â†’ output        â”‚   â”‚
â”‚  â”‚     - No cumulative attention across steps                          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Comparison:                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Original (Summarization):                                          â”‚   â”‚
â”‚  â”‚    Input: [w1, w2, w3, ..., w400]                                   â”‚   â”‚
â”‚  â”‚    Output: [s1, s2, s3, ..., s100]  â† 100 decoder steps            â”‚   â”‚
â”‚  â”‚    Attention: computed 100 times, coverage tracks all 100          â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Proposed (Next Location):                                          â”‚   â”‚
â”‚  â”‚    Input: [loc1, loc2, ..., loc50]                                  â”‚   â”‚
â”‚  â”‚    Output: [next_loc]  â† 1 prediction                               â”‚   â”‚
â”‚  â”‚    Attention: computed 1 time, no coverage needed                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Mathematical Formulations

### Loss Function Formulas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MATHEMATICAL FORMULATIONS                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ORIGINAL NLL LOSS:                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚              1      T                                                â”‚   â”‚
â”‚  â”‚  L_NLL = - â”€â”€â”€â”€â”€â”€â”€ Î£  log P(y_t* | y_{<t}, x) Ã— mask_t              â”‚   â”‚
â”‚  â”‚           T_valid t=1                                                â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    T = max decoder steps                                            â”‚   â”‚
â”‚  â”‚    T_valid = Î£ mask_t (non-padding steps)                           â”‚   â”‚
â”‚  â”‚    y_t* = target word at step t                                     â”‚   â”‚
â”‚  â”‚    mask_t = 1 if step t is not padding                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  ORIGINAL COVERAGE LOSS:                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  c_t = Î£_{t'=0}^{t-1} a_{t'}    (cumulative attention)             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚              1      T                   N                            â”‚   â”‚
â”‚  â”‚  L_cov = - â”€â”€â”€â”€â”€â”€â”€ Î£  [mask_t Ã— Î£  min(a_{t,i}, c_{t,i})]          â”‚   â”‚
â”‚  â”‚           T_valid t=1              i=1                               â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Total: L_total = L_NLL + Î» Ã— L_cov   (Î» = 1.0)                     â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  PROPOSED CROSS-ENTROPY WITH LABEL SMOOTHING:                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Smoothed target distribution:                                       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚         â”Œ 1 - Îµ        if k = y*                                    â”‚   â”‚
â”‚  â”‚  q_k = â”€â”¤                                                            â”‚   â”‚
â”‚  â”‚         â”” Îµ / (K - 1)  if k â‰  y*                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Loss:                                                               â”‚   â”‚
â”‚  â”‚                   K                                                  â”‚   â”‚
â”‚  â”‚  L_smooth = - Î£  q_k Ã— log P(k)                                     â”‚   â”‚
â”‚  â”‚               k=1                                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    Îµ = 0.03 (smoothing factor)                                      â”‚   â”‚
â”‚  â”‚    K = number of classes (locations)                                â”‚   â”‚
â”‚  â”‚    y* = true target location                                        â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Metrics Formulas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    METRICS MATHEMATICAL FORMULATIONS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ROUGE-1 (ORIGINAL):                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Precision:                                                          â”‚   â”‚
â”‚  â”‚             Î£_wâˆˆG min(count(w,G), count(w,R))                       â”‚   â”‚
â”‚  â”‚  P = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚   â”‚
â”‚  â”‚                    Î£_wâˆˆG count(w,G)                                  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Recall:                                                             â”‚   â”‚
â”‚  â”‚             Î£_wâˆˆR min(count(w,G), count(w,R))                       â”‚   â”‚
â”‚  â”‚  R = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚   â”‚
â”‚  â”‚                    Î£_wâˆˆR count(w,R)                                  â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  F1:                                                                 â”‚   â”‚
â”‚  â”‚         2 Ã— P Ã— R                                                    â”‚   â”‚
â”‚  â”‚  F1 = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚   â”‚
â”‚  â”‚         P + R                                                        â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  ACCURACY@K (PROPOSED):                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚           1   N                                                      â”‚   â”‚
â”‚  â”‚  Acc@K = â”€â”€â”€ Î£  ğŸ™(y_i* âˆˆ top_K(P_i))                                â”‚   â”‚
â”‚  â”‚           N  i=1                                                     â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    ğŸ™(Â·) = indicator function (1 if true, 0 otherwise)              â”‚   â”‚
â”‚  â”‚    y_i* = true target for sample i                                  â”‚   â”‚
â”‚  â”‚    top_K(P_i) = K highest probability classes                       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  MRR (PROPOSED):                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚        1   N    1                                                    â”‚   â”‚
â”‚  â”‚  MRR = â”€â”€â”€ Î£  â”€â”€â”€â”€â”€â”€                                                â”‚   â”‚
â”‚  â”‚         N  i=1 rank_i                                                â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Where:                                                              â”‚   â”‚
â”‚  â”‚    rank_i = position of y_i* in sorted predictions (1-indexed)     â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  NDCG@K (PROPOSED):                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  For single-label classification (relevance âˆˆ {0,1}):               â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚             K   rel_i                                                â”‚   â”‚
â”‚  â”‚  DCG@K = Î£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚   â”‚
â”‚  â”‚           i=1 logâ‚‚(i+1)                                              â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  IDCG@K = 1 / logâ‚‚(2) = 1  (ideal: correct answer at position 1)   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  NDCG@K = DCG@K / IDCG@K                                            â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Simplifies to: NDCG@K = 1/logâ‚‚(rank+1) if rank â‰¤ K, else 0        â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Code Comparison

### Loss Function Implementation

```python
# ==============================================================================
# ORIGINAL: Loss Calculation (model.py, lines 249-278)
# ==============================================================================

def _add_seq2seq(self):
    # ... (encoder, attention, decoder setup) ...
    
    with tf.variable_scope('output_projection'):
        # For baseline (no pointer):
        if not self._hps.pointer_gen:
            self._loss = tf.contrib.seq2seq.sequence_loss(
                tf.stack(vocab_scores, axis=1),
                self._target_batch,
                self._dec_padding_mask
            )
        
        # For pointer-generator:
        else:
            loss_per_step = []
            batch_nums = tf.range(0, limit=hps.batch_size)
            
            for dec_step, dist in enumerate(final_dists):
                # Get probability of correct word
                targets = self._target_batch[:, dec_step]
                indices = tf.stack((batch_nums, targets), axis=1)
                gold_probs = tf.gather_nd(dist, indices)
                
                # Negative log likelihood
                losses = -tf.log(gold_probs + 1e-10)  # Add epsilon to avoid log(0)
                loss_per_step.append(losses)
            
            # Average over non-padding positions
            self._loss = _mask_and_avg(loss_per_step, self._dec_padding_mask)
    
    # Coverage loss (optional)
    if hps.coverage:
        with tf.variable_scope('coverage_loss'):
            self._coverage_loss = _coverage_loss(self.attn_dists, self._dec_padding_mask)
            self._total_loss = self._loss + hps.cov_loss_wt * self._coverage_loss

def _mask_and_avg(values, padding_mask):
    """Apply mask and average over sequence."""
    dec_lens = tf.reduce_sum(padding_mask, axis=1)  # [batch]
    values_per_step = [v * padding_mask[:, dec_step] for dec_step, v in enumerate(values)]
    values_per_ex = sum(values_per_step) / dec_lens  # [batch]
    return tf.reduce_mean(values_per_ex)  # scalar

def _coverage_loss(attn_dists, padding_mask):
    """Compute coverage loss."""
    coverage = tf.zeros_like(attn_dists[0])
    covlosses = []
    
    for a in attn_dists:
        covloss = tf.reduce_sum(tf.minimum(a, coverage), [1])  # [batch]
        covlosses.append(covloss)
        coverage += a  # Update coverage
    
    return _mask_and_avg(covlosses, padding_mask)

# ==============================================================================
# PROPOSED: Loss Calculation (train_pointer_v45.py, lines 334-337)
# ==============================================================================

class TrainerV45:
    def __init__(self, config):
        # ...
        
        # Cross-entropy loss with label smoothing
        self.criterion = nn.CrossEntropyLoss(
            ignore_index=0,           # Ignore padding (location ID 0)
            label_smoothing=0.03,     # Smooth labels for regularization
        )
    
    def train_epoch(self):
        self.model.train()
        total_loss = 0.0
        
        for x, y, x_dict in self.train_loader:
            x, y = x.to(self.device), y.to(self.device)
            x_dict = {k: v.to(self.device) for k, v in x_dict.items()}
            
            self.optimizer.zero_grad()
            
            # Forward pass
            logits = self.model(x, x_dict)  # [batch, num_locations]
            
            # Compute loss (cross-entropy with label smoothing)
            loss = self.criterion(logits, y)  # Scalar
            
            # Backward pass
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
```

### Metrics Implementation

```python
# ==============================================================================
# ORIGINAL: ROUGE Evaluation (decode.py uses external ROUGE)
# ==============================================================================

# From decode.py, lines 148-165

def write_for_rouge(reference_sents, decoded_words, ex_index, _rouge_ref_dir, _rouge_dec_dir):
    """Write output to file in format expected by ROUGE."""
    decoded_sents = []
    while len(decoded_words) > 0:
        try:
            fst_period_idx = decoded_words.index(".")
        except ValueError:
            fst_period_idx = len(decoded_words)
        sent = decoded_words[:fst_period_idx + 1]
        decoded_words = decoded_words[fst_period_idx + 1:]
        decoded_sents.append(' '.join(sent))
    
    # Write to files for pyrouge
    ref_file = os.path.join(_rouge_ref_dir, "%06d_reference.txt" % ex_index)
    decoded_file = os.path.join(_rouge_dec_dir, "%06d_decoded.txt" % ex_index)
    
    with open(ref_file, "w") as f:
        for sent in reference_sents:
            f.write(sent + "\n")
    
    with open(decoded_file, "w") as f:
        for sent in decoded_sents:
            f.write(sent + "\n")

# ROUGE computation uses external pyrouge library

# ==============================================================================
# PROPOSED: Classification Metrics (metrics.py)
# ==============================================================================

# From metrics.py

def get_mrr(pred: torch.Tensor, target: torch.Tensor) -> float:
    """Calculate Mean Reciprocal Rank.
    
    Args:
        pred: Predictions tensor [batch_size, num_classes]
        target: Target tensor [batch_size]
    
    Returns:
        MRR score
    """
    # Get sorted indices (descending by probability)
    sorted_indices = torch.argsort(pred, dim=1, descending=True)
    
    # Find rank of correct answer for each sample
    ranks = []
    for i in range(len(target)):
        # Find position where target appears in sorted predictions
        rank = (sorted_indices[i] == target[i]).nonzero()
        if len(rank) > 0:
            ranks.append(1.0 / (rank[0].item() + 1))  # 1-indexed rank
        else:
            ranks.append(0.0)
    
    return sum(ranks) / len(ranks)


def get_ndcg(pred: torch.Tensor, target: torch.Tensor, k: int = 10) -> float:
    """Calculate NDCG@K.
    
    Args:
        pred: Predictions tensor [batch_size, num_classes]
        target: Target tensor [batch_size]
        k: Top-K for NDCG
    
    Returns:
        NDCG@K score
    """
    # Get top-K predictions
    top_k = torch.topk(pred, k=min(k, pred.size(1)), dim=1).indices
    
    ndcg_scores = []
    for i in range(len(target)):
        if target[i] in top_k[i]:
            # Find position (0-indexed)
            position = (top_k[i] == target[i]).nonzero()[0].item()
            # DCG for position (1-indexed in formula)
            dcg = 1.0 / math.log2(position + 2)  # +2 because 0-indexed and log2(1)=0
            # IDCG is 1.0 (ideal: correct at position 1)
            ndcg_scores.append(dcg / 1.0)
        else:
            ndcg_scores.append(0.0)
    
    return sum(ndcg_scores) / len(ndcg_scores)


def calculate_correct_total_prediction(
    pred: torch.Tensor, 
    target: torch.Tensor, 
    k_values: List[int] = [1, 5, 10]
) -> Dict[int, Tuple[int, int]]:
    """Calculate correct and total predictions for Acc@K.
    
    Args:
        pred: Predictions [batch_size, num_classes]
        target: Targets [batch_size]
        k_values: List of K values
    
    Returns:
        Dict mapping K to (correct, total)
    """
    results = {}
    batch_size = len(target)
    
    for k in k_values:
        # Get top-K predictions
        top_k = torch.topk(pred, k=min(k, pred.size(1)), dim=1).indices
        
        # Check if target in top-K
        correct = 0
        for i in range(batch_size):
            if target[i] in top_k[i]:
                correct += 1
        
        results[k] = (correct, batch_size)
    
    return results
```

---

## Example Calculations

### Original: NLL Loss Calculation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               EXAMPLE: NLL LOSS CALCULATION (ORIGINAL)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Target sequence: ["president", "unveils", "plan", "<STOP>"]                â”‚
â”‚  Target IDs: [156, 50000, 234, 3]  (50000 = OOV 'unveils')                 â”‚
â”‚                                                                              â”‚
â”‚  Model predictions at each step:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 1: P(president|x) = 0.15                                       â”‚   â”‚
â”‚  â”‚          L_1 = -log(0.15) = 1.897                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 2: P(unveils|x, president) = 0.08                             â”‚   â”‚
â”‚  â”‚          L_2 = -log(0.08) = 2.526                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 3: P(plan|x, president, unveils) = 0.25                       â”‚   â”‚
â”‚  â”‚          L_3 = -log(0.25) = 1.386                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Step 4: P(<STOP>|x, president, unveils, plan) = 0.40               â”‚   â”‚
â”‚  â”‚          L_4 = -log(0.40) = 0.916                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Total Loss:                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  L = (L_1 + L_2 + L_3 + L_4) / 4                                    â”‚   â”‚
â”‚  â”‚    = (1.897 + 2.526 + 1.386 + 0.916) / 4                            â”‚   â”‚
â”‚  â”‚    = 6.725 / 4                                                       â”‚   â”‚
â”‚  â”‚    = 1.681                                                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Proposed: Cross-Entropy Loss Calculation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EXAMPLE: CROSS-ENTROPY LOSS CALCULATION (PROPOSED)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Alice's trajectory: [101, 205, 150, 312, 150]                              â”‚
â”‚  Target: Gym (ID=89)                                                         â”‚
â”‚  Number of locations: 500                                                    â”‚
â”‚  Label smoothing: Îµ = 0.03                                                   â”‚
â”‚                                                                              â”‚
â”‚  Model output probabilities:                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  P(loc=89|x) = 0.35   (probability for Gym)                         â”‚   â”‚
â”‚  â”‚  P(loc=101|x) = 0.25  (probability for Home)                        â”‚   â”‚
â”‚  â”‚  P(loc=150|x) = 0.20  (probability for Office)                      â”‚   â”‚
â”‚  â”‚  P(other) = 0.20      (distributed among other 497 locations)       â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Standard Cross-Entropy (without smoothing):                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  L_CE = -log P(89|x) = -log(0.35) = 1.050                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  With Label Smoothing (Îµ = 0.03):                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Target distribution:                                                â”‚   â”‚
â”‚  â”‚    q(89) = 1 - 0.03 = 0.97                                          â”‚   â”‚
â”‚  â”‚    q(kâ‰ 89) = 0.03 / (500-1) = 0.00006 for each                     â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Smoothed loss:                                                      â”‚   â”‚
â”‚  â”‚    L_smooth = -q(89) Ã— log P(89) - Î£_{kâ‰ 89} q(k) Ã— log P(k)        â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    Main term: -0.97 Ã— log(0.35) = -0.97 Ã— (-1.050) = 1.019         â”‚   â”‚
â”‚  â”‚    Smoothing term: â‰ˆ 0.03 Ã— avg(-log P(k)) â‰ˆ 0.03 Ã— 6.0 â‰ˆ 0.180   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚    L_smooth â‰ˆ 1.019 + 0.180 = 1.199                                 â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Proposed: Metrics Calculation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXAMPLE: METRICS CALCULATION (PROPOSED)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  3 test samples:                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 1: True=89 (Gym)                                             â”‚   â”‚
â”‚  â”‚    Model top-5 predictions: [150, 89, 101, 312, 205]                â”‚   â”‚
â”‚  â”‚    Rank of 89 = 2                                                    â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 2: True=101 (Home)                                           â”‚   â”‚
â”‚  â”‚    Model top-5 predictions: [101, 150, 89, 205, 312]                â”‚   â”‚
â”‚  â”‚    Rank of 101 = 1                                                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 3: True=205 (Coffee)                                         â”‚   â”‚
â”‚  â”‚    Model top-5 predictions: [150, 101, 89, 312, 205]                â”‚   â”‚
â”‚  â”‚    Rank of 205 = 5                                                   â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Acc@1 Calculation:                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 1: 89 at rank 2 â†’ NOT in top-1 â†’ 0                          â”‚   â”‚
â”‚  â”‚  Sample 2: 101 at rank 1 â†’ IN top-1 â†’ 1                             â”‚   â”‚
â”‚  â”‚  Sample 3: 205 at rank 5 â†’ NOT in top-1 â†’ 0                         â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Acc@1 = (0 + 1 + 0) / 3 = 0.333 = 33.3%                           â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  Acc@5 Calculation:                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 1: 89 at rank 2 â†’ IN top-5 â†’ 1                              â”‚   â”‚
â”‚  â”‚  Sample 2: 101 at rank 1 â†’ IN top-5 â†’ 1                             â”‚   â”‚
â”‚  â”‚  Sample 3: 205 at rank 5 â†’ IN top-5 â†’ 1                             â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Acc@5 = (1 + 1 + 1) / 3 = 1.000 = 100%                            â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  MRR Calculation:                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 1: 1/rank = 1/2 = 0.500                                     â”‚   â”‚
â”‚  â”‚  Sample 2: 1/rank = 1/1 = 1.000                                     â”‚   â”‚
â”‚  â”‚  Sample 3: 1/rank = 1/5 = 0.200                                     â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  MRR = (0.500 + 1.000 + 0.200) / 3 = 0.567                         â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â”‚  NDCG@5 Calculation:                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Sample 1: rank=2 â†’ 1/logâ‚‚(2+1) = 1/logâ‚‚(3) = 0.631                â”‚   â”‚
â”‚  â”‚  Sample 2: rank=1 â†’ 1/logâ‚‚(1+1) = 1/logâ‚‚(2) = 1.000                â”‚   â”‚
â”‚  â”‚  Sample 3: rank=5 â†’ 1/logâ‚‚(5+1) = 1/logâ‚‚(6) = 0.387                â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  NDCG@5 = (0.631 + 1.000 + 0.387) / 3 = 0.673                      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary

| Aspect | Original | Proposed |
|--------|----------|----------|
| **Loss Function** | NLL (per-step average) | Cross-Entropy |
| **Coverage Loss** | Yes (optional, Î»=1.0) | No (not needed) |
| **Label Smoothing** | No | Yes (Îµ=0.03) |
| **Padding Handling** | Manual masking | ignore_index |
| **Primary Metrics** | ROUGE-1, ROUGE-2, ROUGE-L | Acc@K |
| **Secondary Metrics** | - | MRR, NDCG@K |
| **Metric Type** | Text overlap/similarity | Classification accuracy |
| **External Tools** | pyrouge | Built-in PyTorch |

---

*Next: [10_DEFAULT_CONFIGURATION.md](10_DEFAULT_CONFIGURATION.md) - Default hyperparameter comparison*
