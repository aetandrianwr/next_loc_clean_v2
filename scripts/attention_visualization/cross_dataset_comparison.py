#!/usr/bin/env python3
"""
Cross-Dataset Comparison for Attention Visualization Experiment.

This script generates comparative visualizations and tables between
the DIY and Geolife datasets for the PointerGeneratorTransformer model.

Scientific Purpose:
===================
Compare attention mechanisms across datasets with different characteristics:
- DIY: Check-in based location data (urban mobility)
- Geolife: GPS trajectory data (continuous movement)

Output:
=======
- Comparative visualizations (PDF + PNG)
- Summary tables (CSV + LaTeX)
- Statistical comparison metrics

Author: PhD Thesis Experiment
Date: 2026
"""

import os
import sys
import json
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Set publication-quality defaults
plt.rcParams.update({
    'font.family': 'DejaVu Sans',
    'font.size': 10,
    'axes.labelsize': 11,
    'axes.titlesize': 12,
    'xtick.labelsize': 9,
    'ytick.labelsize': 9,
    'legend.fontsize': 9,
    'figure.dpi': 150,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'savefig.pad_inches': 0.1,
})

# Project paths
PROJECT_ROOT = Path(__file__).parent.parent.parent
RESULTS_DIR = PROJECT_ROOT / 'scripts' / 'attention_visualization' / 'results'


def load_experiment_data(dataset: str) -> dict:
    """Load experiment results for a dataset."""
    result_dir = RESULTS_DIR / dataset
    
    data = {
        'metadata': json.load(open(result_dir / 'experiment_metadata.json')),
        'statistics': pd.read_csv(result_dir / 'attention_statistics.csv'),
        'position_attention': pd.read_csv(result_dir / 'position_attention.csv'),
        'selected_samples': pd.read_csv(result_dir / 'selected_samples.csv'),
    }
    
    return data


def create_comparison_table(diy_data: dict, geolife_data: dict, output_dir: Path):
    """Create a comprehensive comparison table."""
    
    # Extract statistics
    diy_stats = diy_data['statistics'].set_index('Metric')['Value']
    geo_stats = geolife_data['statistics'].set_index('Metric')['Value']
    
    comparison = {
        'Metric': [
            'Dataset',
            'Test Samples',
            'Model Parameters',
            'Prediction Accuracy (%)',
            'Mean Gate Value',
            'Gate Std Dev',
            'Gate (Correct)',
            'Gate (Incorrect)',
            'Mean Pointer Entropy',
            'Pointer Entropy Std Dev',
            'Most Recent Position Attention',
            'd_model',
            'num_heads',
            'num_layers',
        ],
        'DIY': [
            'DIY Check-in',
            diy_stats['Total Samples'],
            f"{diy_data['metadata']['model_config']['d_model'] * 16895:.0f}",  # Approximate
            diy_stats['Prediction Accuracy (%)'],
            diy_stats['Mean Gate Value'],
            diy_stats['Gate Std Dev'],
            diy_stats['Gate (Correct Predictions)'],
            diy_stats['Gate (Incorrect Predictions)'],
            diy_stats['Mean Pointer Entropy'],
            diy_stats['Pointer Entropy Std Dev'],
            diy_stats['Most Recent Position Attention'],
            diy_data['metadata']['model_config']['d_model'],
            diy_data['metadata']['model_config']['nhead'],
            diy_data['metadata']['num_layers'],
        ],
        'Geolife': [
            'GeoLife GPS',
            geo_stats['Total Samples'],
            f"{geolife_data['metadata']['model_config']['d_model'] * 4618:.0f}",  # Approximate
            geo_stats['Prediction Accuracy (%)'],
            geo_stats['Mean Gate Value'],
            geo_stats['Gate Std Dev'],
            geo_stats['Gate (Correct Predictions)'],
            geo_stats['Gate (Incorrect Predictions)'],
            geo_stats['Mean Pointer Entropy'],
            geo_stats['Pointer Entropy Std Dev'],
            geo_stats['Most Recent Position Attention'],
            geolife_data['metadata']['model_config']['d_model'],
            geolife_data['metadata']['model_config']['nhead'],
            geolife_data['metadata']['num_layers'],
        ]
    }
    
    df = pd.DataFrame(comparison)
    
    # Save CSV
    df.to_csv(output_dir / 'cross_dataset_comparison.csv', index=False)
    
    # Save LaTeX
    latex_str = df.to_latex(index=False, escape=False,
                            caption='Cross-Dataset Attention Mechanism Comparison',
                            label='tab:cross_dataset_comparison')
    with open(output_dir / 'cross_dataset_comparison.tex', 'w') as f:
        f.write(latex_str)
    
    return df


def plot_gate_comparison(diy_data: dict, geolife_data: dict, output_dir: Path):
    """Create side-by-side gate value comparison."""
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # Extract gate values from metadata
    diy_gate = float(diy_data['metadata']['gate_mean'])
    diy_gate_std = float(diy_data['metadata']['gate_std'])
    geo_gate = float(geolife_data['metadata']['gate_mean'])
    geo_gate_std = float(geolife_data['metadata']['gate_std'])
    
    # Left: Bar comparison
    ax = axes[0]
    datasets = ['DIY', 'Geolife']
    gate_means = [diy_gate, geo_gate]
    gate_stds = [diy_gate_std, geo_gate_std]
    
    colors = ['#2ecc71', '#3498db']
    bars = ax.bar(datasets, gate_means, yerr=gate_stds, capsize=8, 
                  color=colors, edgecolor='black', linewidth=1.5, alpha=0.8)
    
    ax.set_ylabel('Mean Gate Value')
    ax.set_title('Pointer Gate Value Comparison')
    ax.set_ylim(0, 1)
    
    # Add value labels
    for bar, mean, std in zip(bars, gate_means, gate_stds):
        ax.annotate(f'{mean:.3f}Â±{std:.3f}',
                   xy=(bar.get_x() + bar.get_width()/2, mean + std + 0.02),
                   ha='center', fontsize=10, fontweight='bold')
    
    # Add interpretation line
    ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='Equal pointer/generation')
    ax.legend(loc='lower right')
    
    # Right: Position attention comparison
    ax = axes[1]
    
    diy_pos = diy_data['position_attention']['Mean Attention'].astype(float)
    geo_pos = geolife_data['position_attention']['Mean Attention'].astype(float)
    
    x = np.arange(min(len(diy_pos), len(geo_pos), 15))
    width = 0.35
    
    ax.bar(x - width/2, diy_pos[:len(x)], width, label='DIY', color='#2ecc71', alpha=0.8)
    ax.bar(x + width/2, geo_pos[:len(x)], width, label='Geolife', color='#3498db', alpha=0.8)
    
    ax.set_xlabel('Position from Sequence End')
    ax.set_ylabel('Mean Attention Weight')
    ax.set_title('Position-wise Attention Comparison')
    ax.legend()
    ax.set_xticks(x)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'cross_dataset_gate_comparison.png')
    plt.savefig(output_dir / 'cross_dataset_gate_comparison.pdf')
    plt.close()


def plot_attention_pattern_comparison(diy_data: dict, geolife_data: dict, output_dir: Path):
    """Compare attention patterns across datasets."""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. Position attention distribution
    ax = axes[0, 0]
    diy_pos = diy_data['position_attention']['Mean Attention'].astype(float).values
    geo_pos = geolife_data['position_attention']['Mean Attention'].astype(float).values
    
    max_len = min(len(diy_pos), len(geo_pos), 20)
    x = np.arange(max_len)
    
    ax.plot(x, diy_pos[:max_len], 'o-', color='#2ecc71', linewidth=2, markersize=6, label='DIY')
    ax.plot(x, geo_pos[:max_len], 's-', color='#3498db', linewidth=2, markersize=6, label='Geolife')
    ax.set_xlabel('Position from End (t-k)')
    ax.set_ylabel('Mean Attention Weight')
    ax.set_title('Recency Effect in Pointer Attention')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. Recency ratio comparison
    ax = axes[0, 1]
    
    # Calculate cumulative attention for top-k positions
    k_values = range(1, 11)
    diy_cumsum = [diy_pos[:k].sum() for k in k_values]
    geo_cumsum = [geo_pos[:k].sum() for k in k_values]
    
    ax.plot(k_values, diy_cumsum, 'o-', color='#2ecc71', linewidth=2, markersize=6, label='DIY')
    ax.plot(k_values, geo_cumsum, 's-', color='#3498db', linewidth=2, markersize=6, label='Geolife')
    ax.set_xlabel('Number of Most Recent Positions (k)')
    ax.set_ylabel('Cumulative Attention')
    ax.set_title('Attention Concentration in Recent History')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. Gate value by prediction outcome
    ax = axes[1, 0]
    
    diy_stats = diy_data['statistics'].set_index('Metric')['Value']
    geo_stats = geolife_data['statistics'].set_index('Metric')['Value']
    
    x = np.arange(2)
    width = 0.35
    
    diy_gates = [float(diy_stats['Gate (Correct Predictions)']), 
                 float(diy_stats['Gate (Incorrect Predictions)'])]
    geo_gates = [float(geo_stats['Gate (Correct Predictions)']), 
                 float(geo_stats['Gate (Incorrect Predictions)'])]
    
    ax.bar(x - width/2, diy_gates, width, label='DIY', color='#2ecc71', alpha=0.8)
    ax.bar(x + width/2, geo_gates, width, label='Geolife', color='#3498db', alpha=0.8)
    ax.set_xticks(x)
    ax.set_xticklabels(['Correct', 'Incorrect'])
    ax.set_ylabel('Mean Gate Value')
    ax.set_title('Gate Value by Prediction Outcome')
    ax.legend()
    ax.set_ylim(0, 1)
    
    # 4. Summary metrics radar-like comparison
    ax = axes[1, 1]
    
    metrics = ['Accuracy', 'Gate Mean', 'Entropy (norm)', 'Recency (pos 0)']
    
    diy_vals = [
        float(diy_stats['Prediction Accuracy (%)']) / 100,
        float(diy_stats['Mean Gate Value']),
        float(diy_stats['Mean Pointer Entropy']) / 4,  # Normalize to ~0-1
        float(diy_stats['Most Recent Position Attention']),
    ]
    
    geo_vals = [
        float(geo_stats['Prediction Accuracy (%)']) / 100,
        float(geo_stats['Mean Gate Value']),
        float(geo_stats['Mean Pointer Entropy']) / 4,
        float(geo_stats['Most Recent Position Attention']),
    ]
    
    x = np.arange(len(metrics))
    width = 0.35
    
    ax.bar(x - width/2, diy_vals, width, label='DIY', color='#2ecc71', alpha=0.8)
    ax.bar(x + width/2, geo_vals, width, label='Geolife', color='#3498db', alpha=0.8)
    ax.set_xticks(x)
    ax.set_xticklabels(metrics, rotation=15, ha='right')
    ax.set_ylabel('Normalized Value')
    ax.set_title('Summary Metrics Comparison')
    ax.legend()
    ax.set_ylim(0, 1)
    
    plt.suptitle('Cross-Dataset Attention Pattern Analysis', fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / 'cross_dataset_attention_patterns.png')
    plt.savefig(output_dir / 'cross_dataset_attention_patterns.pdf')
    plt.close()


def generate_summary_statistics(diy_data: dict, geolife_data: dict, output_dir: Path):
    """Generate comprehensive summary statistics."""
    
    summary = []
    
    # Key findings
    diy_gate = float(diy_data['metadata']['gate_mean'])
    geo_gate = float(geolife_data['metadata']['gate_mean'])
    
    findings = {
        'Finding': [
            'Higher pointer reliance',
            'Lower pointer entropy',
            'Stronger recency bias',
            'Better accuracy',
            'Gate differential (correct vs incorrect)',
        ],
        'DIY': [
            f"Gate: {diy_gate:.3f}",
            f"Entropy: {diy_data['metadata']['pointer_entropy_mean']:.3f}",
            f"Pos-0: {float(diy_data['statistics'].set_index('Metric')['Value']['Most Recent Position Attention']):.4f}",
            f"{diy_data['metadata']['accuracy']*100:.2f}%",
            f"{float(diy_data['statistics'].set_index('Metric')['Value']['Gate (Correct Predictions)']) - float(diy_data['statistics'].set_index('Metric')['Value']['Gate (Incorrect Predictions)']):.4f}",
        ],
        'Geolife': [
            f"Gate: {geo_gate:.3f}",
            f"Entropy: {geolife_data['metadata']['pointer_entropy_mean']:.3f}",
            f"Pos-0: {float(geolife_data['statistics'].set_index('Metric')['Value']['Most Recent Position Attention']):.4f}",
            f"{geolife_data['metadata']['accuracy']*100:.2f}%",
            f"{float(geolife_data['statistics'].set_index('Metric')['Value']['Gate (Correct Predictions)']) - float(geolife_data['statistics'].set_index('Metric')['Value']['Gate (Incorrect Predictions)']):.4f}",
        ],
        'Interpretation': [
            'DIY shows stronger copy mechanism preference',
            'DIY has more focused attention distribution',
            'DIY attends more to recent locations',
            'DIY dataset achieves higher accuracy',
            'Positive differential indicates gate usefulness',
        ]
    }
    
    df = pd.DataFrame(findings)
    df.to_csv(output_dir / 'key_findings.csv', index=False)
    
    # LaTeX
    latex_str = df.to_latex(index=False, escape=False,
                            caption='Key Findings from Attention Analysis',
                            label='tab:key_findings')
    with open(output_dir / 'key_findings.tex', 'w') as f:
        f.write(latex_str)
    
    return df


def main():
    """Run cross-dataset comparison analysis."""
    print("=" * 60)
    print("CROSS-DATASET ATTENTION COMPARISON")
    print("=" * 60)
    
    # Load data
    print("\nLoading experiment data...")
    diy_data = load_experiment_data('diy')
    geolife_data = load_experiment_data('geolife')
    
    # Output directory
    output_dir = RESULTS_DIR
    
    # Generate comparison table
    print("Generating comparison table...")
    df_comparison = create_comparison_table(diy_data, geolife_data, output_dir)
    print(df_comparison.to_string(index=False))
    
    # Generate visualizations
    print("\nGenerating comparison visualizations...")
    plot_gate_comparison(diy_data, geolife_data, output_dir)
    plot_attention_pattern_comparison(diy_data, geolife_data, output_dir)
    
    # Generate summary statistics
    print("Generating summary statistics...")
    df_findings = generate_summary_statistics(diy_data, geolife_data, output_dir)
    
    print("\n" + "=" * 60)
    print("KEY FINDINGS")
    print("=" * 60)
    print(df_findings.to_string(index=False))
    
    print(f"\nResults saved to: {output_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()
